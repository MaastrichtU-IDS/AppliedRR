---
title: 'Applied Research: Simple and Multiple Linear Regression'
author:
- name: Carlos Utrilla Guerrero
date: "6/08/2021"
output:
  html_document: default
description: Working your way through a basic analysis, in a reproducible manner.
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


![](https://maastrichtu-ids.github.io/AppliedRR/pics/logoIDS.png)


# WELCOME


In workshop #5 you’ll practice constructing and understanding regression models.


* Create simple and multiple linear regression models with `lm()`

* Explore the outputs of your models, including coefficients, confidence intervals, and p-values.

* Explore the residuals and fitted values of a linear model.

* Use your model to make predictions for new data,

---

## IMPORT DATASET

![](https://johnmuschelli.com/neuroc_talk/figures/grandma_meme.jpg)

The baseball.csv file contains *Major League Baseball Data* from the 1986 and 1987 seasons. The data originally come from the `ISLR` package.

+ [download](https://docs.google.com/spreadsheets/d/1644rcEM0Jk8qN1l4_2aewfgAuNQ2jg0cJNgSX--ebXM/edit#gid=0)

Using the following command in R, load the baseball.excel data into R and store it as a new object called hitters.

```{r}
library(readxl) # import library
baseball <- read_excel("Baseball.xlsx") # import the baseball.xlsx file
```

_Note that this command assumes that you have the `readxl` package already installed. If you haven’t done this in previous meetings but imported the file differently, then you first have to run the command `install.packages(“readxl”)`._

---

## DATA PREPARATION

First, you want to get to know the data set and see whether importing the dataset was successful and worked out correctly. To do this, first take a look at the first 6 rows of the dataset(s) by printing it/them to the console. 

**Which command allows you to do this? The output should look like the table below:**

```{r echo=TRUE}
head(baseball,6)
```

Next, you take a look at the *structure* of the data in order to see the number of observations the dataset `baseball` has, as well as the number and type of variables.

**Which code can you use? The output should look like...or give you exactly this information!**

```{r echo=FALSE}
str(baseball)
```


Now, you see that this data contains 50 observations and 20 variables. Also, we can clearly see that most of them are numerical and few of them are `characters` _(characters = text/string)_. Furthermore, none of the numerical variables are categorical ones, while all of the character variables are categorical. However, since the categorical variables are considered characters, they can’t be effectively used in further analysis. Therefore, we need to convert them into factors. 

_Note, due to the fact that we import the file from excel into R, R does not directly recognize categorical variables as factor and therefore we need to convert them ourselves._

### Exercise 1: Can you please convert all three categorical variables into a factor? Remember from workshop 2 the code? 


```{r echo=FALSE}
# convert the variable "League" into factor
baseball$League <- factor(baseball$League)
# convert the variable "Division" into factor
baseball$Division <- factor(baseball$Division)
# convert the variable "NewLeague" into factor
baseball$NewLeague <- factor(baseball$Division)
```

Does the code class tell you that all the 3 categorical variables have been changed into a factor? If yes, then perfect! Another way to check it is having a look again the structure of our baseball dataset. The difference to `class()` is that the next command also immediately tells you how many levels the individual factor variables have.

```{r}
str(baseball)
```


Next thing to do is to check for **missing values**. You already know that you can use the command `is.na()` in R in order to see if there are missing values. If you run it, you will see that there are any NA values in our dataset; that is perfect! Nonetheless, a good point of `summary()` is that also will give you a count of NA values.


---

## DATA EXPLORATION

![](https://cdn-images-1.medium.com/fit/t/1600/480/1*uCVjc-xE2uzh2hhtKURh2w.jpeg)

Great. It seems like we are ready to run some basic summary statistics of our dataset now, in order to get a first impression of the data distribution. 

**Which code can you use? The output should look like...or give you exactly this information!**

```{r echo=FALSE}
summary(baseball)
```

At this point, we are very interested on exploring the Baseball dataset. We are wondering if **there is a relationship between the number of `Hits` a player had and his `Salary.`** Lets create a scatterplot for this. Try this command in your R console

```{r}
library(ggplot2) # import ggplot2 library for visualisation
ggplot(baseball, aes(x = Hits, y = Salary)) +
  geom_point(col = "pink") +
  labs(title = "Is there any relationship between baseball player Hits vs Salary?",
       subtitle = "Plotting your data is the first step to figuring out",
       caption = "R course Venlo Course")
```


_Note again, that library() only works if you have already installed the related package previously, in this case `install.packages(“ggplot2”)`._

The y-axis is the amount of salary **(the dependent variable is always on the y-axis)** and the x-axis is the total Hits. Each pink dot represents one player the baseball dataset. Glancing at this data, you probably notice that salary are higher for players that hit a lot. That’s interesting to know, but by how much is the salary higher?
How can we answer with some degree of certainty how much a player typically earns when he hits a certain amount of balls? We can do this by drawing a line through the chart above, one that runs roughly through the middle of all the data points. We do this as follows:


```{r}
ggplot(baseball, aes(x = Hits, y = Salary)) +
  geom_point(col = "pink") +
  geom_smooth(method='lm',  # Add linear regression line 
              se = FALSE) + # # Don't add shaded confidence region
  labs(title = "Is there any relationship between baseball player Hits vs Salary?",
       subtitle = "Plotting your data with the best fitted line",
       caption = "R course Venlo Course")

```

_You might get the error `geom_smooth()`using formula 'y ~ x'`. Ignore this error. Despite this error you get the correct graph in the plots window._

The resulting blue line (see plot below) is called the regression line and it’s the line that best fits the data. In other words, the blue line is the best explanation of the relationship between the independent variable `(Hits)` and dependent variable `(Salary)`.

### Exercise 2: Based on this plot, do you expect there to be a relationship between these variables? Which kind of test would you run in order to quantitatively support your answer?

In addition to drawing the line, In statistics, once you have calculated the slope and y-intercept to form the best-fitting regression line in a scatterplot, you can then interpret their values:


$Y$= $\beta_{0}$ +$\beta_{1}$*$x_{1}$ + $\varepsilon$


$Salary$ = $\beta_{0}$ +$\beta_{1}$*$x_{Hits}$ + $\varepsilon$


In this case, $\beta_{0}$ is the intercept, the value from where you start measuring (or in the figure the value where the regression line starts when X (in this case the `Hits` = 0). $\beta_{1}$ is the slope of the best-fitting line. The slope measures the change of `Salary` with respect to the `Hits` as predicted by the line. 

Stated differently, the line illustrates the salary increase ($\beta_{1}$) for every one more hits a player did achieve it. 

At this point, I am kind of curious about the relationship: is there any possibility to suggest that we can predict the amount of money player earn and number of hits? 

We are going to create a model that uses the number of `hits` a player does as an indicator of increasing in player salary `Salary`. I believe this model makes sense since we firstly show a linear relationship between both variables and I would assume that the better a player does, the higher increase in salary. Let's go ahead and try to create our first simple linear regression

---

## SIMPLE LINEAR REGRESSION

![](https://miro.medium.com/max/888/1*guak1sQTh5sAf46NMzbQig.jpeg)

**What is a linear regression?**

A linear regression is a statistical model that analyzes the relationship between a dependent variable (Y) and one or more other variables (often explanatory variables or independent $x_{1} + x_{2} + \cdots + x_{n}$). You make this kind of relationships in your head all the time, for example when you calculate the age of a child based on her height, you are assuming the older she is, the taller she will be. Or just the example taken above as a way to hypothesize an expected relationship between `Salary` and `Hits.`

As mentioned before, we attempt to create a linear model to see this relationship. This model will predict `Salary`, using, in our case, the explanatory variable `hits`.


Using the guide below, we are going to conduct a regression analysis predicting a player’s `Salary` as a function of his `Hits` value. We are going to save the result to an object called `baseball_simple`:

```{r}
baseball_simple <- lm(formula = Salary ~ Hits, # linear regression formula (Dependent ~ Independent)
                data = baseball) # the name of my dataset
```

With the command `summary(baseball_simple)` you can see detailed information on the model’s performance and coefficients.

```{r}
summary(baseball_simple)
```

### Interpretation

R will give you always the following information for model output:

*Call:*

This will show you what you actually just run. The linear equation of:

`lm(formula = Salary ~ Hits, data = baseball)`

*Residuals:*

We can see the residuals of the `baseball_simple` as following:

```{r include=FALSE}
baseball_simple$residuals
```

Residuals are essentially the difference between the observed values (salary) and the response values that the model predicted. The Residuals section of the model output breaks it down into 5 summary points. Later on when making a residual plot, you are going to see that the distribution of the residuals do not appear to be strongly symmetrical. That means that the model gives you certain predictions that fall far away from the actual observed points. We could take this further consider plotting the residuals to see whether this normally distributed, etc. but will skip this for this example for the moment.


*Coefficients*
We can see the Coefficients of the `baseball_simple` as following:


```{r}
baseball_simple$coefficients
```

Thus, we have a our mathematical equation as `salary` variables as our dependent variable and our explanatory variable `Hits`.

Salary=B0+B1*Hits

$Salary$ = $\beta_{0}$ +$\beta_{1}$*$x_{Hits}$ + $\varepsilon$


$Salary$ = $262.886$ +$3.19$*$x_{Hits}$


**Intercept:** 


This values will be always in the equation, unless you explictly erase it from the model

**Hits:**

One variable included into our linear model. In this particular case we just have added one.
- Estimate values: this is giving us our estimated coefficients (betas) and this is the parameter that we need to interpret. So the first one here is given 262.886 that is our intercept value (B0). And what does it means? It is the average value for `Salary` when `Hits` is zero. So what is saying is when `Hits` is zero, we would expect an increase of the players salary of 262.886 dollar on average. However, do not care much about it because it usually does mean nothing in real life. The next coefficient 3.19 corresponds to (B1). This is really important and it tells us, in practical sense, our meaning about the equation. It is called *slope* and it shows us the numerical relationship between our two variables. And what does it mean in general?  Given a one unit increase in Hits (X independent variable) there will be an expected change in Salary(y), on average of 3.195 units. What does means in our case? For one `Hits` increase that baseball players does, we expect them to win 3.195 more dollars in their salary on average. You might notice that we can say that cause we have two continuous variable. So this is the most tricky part to get when interpreting your model results so take your time to fully understand it!



### Exercise 3 – You are asked to answer the question: “Is there a relationship between the number of home runs a player scores and salary” using simple linear regression. 


**1. Create a scatterplot showing the relationship (including a line) between HmRun and Salary using the code just learned. The output should look like this:** 

```{r echo=FALSE}
ggplot(baseball, aes(x = HmRun, y = Salary)) +
  geom_point(col = "pink") +
  geom_smooth(method='lm',  # Add linear regression line 
              se = FALSE) + # # Don't add shaded confidence region
  labs(title = "Is there any relationship between baseball player HmRun vs Salary",
       subtitle = "Plotting your data with best fitted line",
       caption = "R course Venlo Course")
```

**2.	Conduct a regression analysis predicting a player’s Salary as a function of its HmRun value. Save the result to an object called baseball_simple1 and ask R to give you the output (which should look like below). Interpret the output.**

```{r echo=FALSE}
baseball_simple1 <- lm(formula = Salary ~ HmRun, # linear regression formula (Dependent ~ Independent)
                data = baseball) # the name of my dataset
```


**3. Use the `summary()` function to print additional summary information from your `baseball_simple1` object.**

```{r echo=FALSE}
summary(baseball_simple1)
```

**4. Interpret the quality of the model based on your `baseball_simple1` model result please.**

**5. Using the code below, plot the relationship between the model fitted values and the observed values.**

```{r}
# Create scatterplot for observed vs fitted 
ggplot(data = baseball, aes(x = Salary, y = baseball_simple1$fitted.values)) +  
  geom_point() +
  geom_abline(slope = 1, intercept = 0, col = "red") +
  labs(title = "Relationship between model fits (predicted) and observed Salaries",
       subtitle = "Simple Regression = Salary ~ Hits",
       caption = "R course for Applied Research", y = 'Predicted (Fitted) Salary', x = 'Observed Salary') +
  geom_segment(aes(x = Salary, y = baseball_simple1$fitted.values, xend = Salary, yend = baseball_simple1$fitted.values), 
               col = "red") +
  xlim(c(-300, 3000)) +
  ylim(c(-300, 3000))
```


A nice tutorial for a simple regression is [here](https://www.datacamp.com/community/tutorials/linear-regression-R)


---

## MULTIPLE REGRESSION

![](https://miro.medium.com/max/800/0*_9IsvpJHqgzSSMqY.jpg)

Multiple linear regression is an extension of simple linear regression. It is used to predict a dependent variable (y) on the basis of multiple explanatory/independent variables (x).

When including four predictor variables (x), the prediction of y is expressed by the following equation:

$Salary$= $\beta_{0}$ +$\beta_{1}$*$x_{1}$ +$\beta_{2}$*$x_{2}$ +$\beta_{3}$*$x_{3}$ +$\beta_{4}$*$x_{4}$ + $\varepsilon$





The “$\beta$” values are called the regression weights (or $\beta$ coefficients). They measure the association between the explanatory variables and the dependent variable.



### Building the model

We want to create a model for estimating the players salary based on the following variables from the baseball file:
1.	`Hits` - Number of hits in year
2.	`CWalks` - Number of walks during his career
3.	`Assists` - Number of assists in year
4.	`Errors` - Number of errors in year

To do this, use the `formula = ‘y ~ x1 + x2 + x3 + Errors’` notation. Assign the result to an object called baseball_multiple. 


```{r}
baseball_multiple <- lm(formula = Salary ~ Hits + CWalks + Assists + Errors, # linear regression formula (Dependent ~ Independent)
                data = baseball) # the name of my dataset
```


Again, create a summary() `baseball_multiple` in order to check its summary result:

```{r echo=FALSE}
summary(baseball_multiple)
```

---
This work is licensed under the [CC BY-NC 4.0 Creative Commons License](http://creativecommons.org/licenses/by-nc/4.0/).